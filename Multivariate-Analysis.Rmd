---
title: "Multivariate Analysis"
author: "Isabella Chittumuri"
date: "9/29/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents")
setwd("~/Documents/Hunter College/Fall 2020/Stat 717/HW")
```

# 3.11 Use the calcium data in Table 3.4:

```{r}
# Create Table 3.4 calcium matrix
calcium <- matrix(c(35,35,40,10,6,20,35,35,35,30,3.5,4.9,30,2.8,2.7,2.8,4.6,10.9,8,1.6,2.8,2.7,4.38,3.21,2.73,2.81,2.88,2.90,3.28 ,3.2), nrow=10, ncol=3)
dimnames(calcium) <- list(NULL, c("V1", "V2", "V3"))
```

## (a) Find the generalized sample variance |S| as in (3.77).

```{r}
# Generalized sample variance
calcium_cov <- cov(calcium)
det(calcium_cov)
```

## (b) Find the total sample variance tr(S) as in (3.78).

```{r}
# Total sample variance 
sum(diag(calcium_cov))
```

# 3.17 Define the following linear combinations for the variables in Table 3.4:
      $z_1 = y_1 + y_2 + y_3$
      $z_2 = 2y_1 - 3y_2 + 2y_3$
      $z_3 = -y_1 - 2y_2 - 3y_3$
      
## (a) Find $\bar{z}$ and $S_z$ using (3.62) and (3.64).

```{r}
# zbar
calcium_ybar <- apply(calcium,2, mean); calcium_ybar
calcium_A <- matrix(c(1, 1, 1, 2, -3, 2, -1, -2, -3), nrow = 3, ncol = 3, byrow = T); calcium_A
calcium_zbar <- calcium_A %*% calcium_ybar; calcium_zbar
```

```{r}
# S_z sample variance
calcium_sample_var <- calcium_A %*% calcium_cov %*% t(calcium_A); calcium_sample_var
```

## (b) Find $R_z$ from $S_z$ using (3.37).

```{r}
library(matlab)

# $R_z$
diag(calcium_sample_var, names=T)
n <- sqrt(diag(calcium_sample_var,names = T))
calcium_D <- diag(n); calcium_D
calcium_D_inv <- solve(calcium_D)

calcium_Rz <- calcium_D_inv %*% calcium_sample_var %*% calcium_D_inv; calcium_Rz
```

# 4.23 The data are given in Table 4.2. Check each of the six variables for univanate normality using the following tests: Q-Q plots, histograms, 2-dimensional scatter plots, chi-square plot, and Shapiro-Wilks test.

```{r}
hematol <- read.table("T4_2_HEMATOL.dat")
 
# Q-Q plots
par(mfrow=c(2,2))
for (i in 1:6) {
  qqnorm(hematol[,i],main=names(hematol)[i]) 
  qqline(hematol[,i])
}
```

The Q-Q plots tell us that most of the variables are normal with a few deviations towards the right and left ends of the plots. The hematology variables that seem the more normal are "Hemoglobin Concentration" (V1), "Lymphocyte Count" (V4), and "Neutrophil Count" (V5). 

```{r}
# Histograms
for (i in 1:6) {
  hist(hematol[,i],main=names(hematol)[i]) 
}
par(mfrow=c(1,1))
```
 
The Histogram plots show us that most of the variables are skewed either to the right or left. "Hemoglobin Concentration" (V1), "Packed Cell Volume" (V2), and "Neutrophil Count" (V5) appear to have a normal distribution. 

```{r}
# Pairwise scatter plots
pairs(hematol[,-5])
```
 
The pairwise scatter plot allows us to see the relationship between any two variables from the hematology dataset. From this, we can see that the relationship between "Hemoglobin Concentration" (V1) and "Packed Cell Volume" (V2), as well as "White Blood Cell Count" (V3) and "Lymphocyte Count" (V4) are positively linear. The other pairwise relationships seem to have little to no relationship.

```{r}
# Chi Square plot 
chisqplot <- function(data=hematol[,-5],percent=50,alpha=0.05)
{
  # Vector of the means
  xbar <- apply(data,2,mean)
  
  # Unbiased variance-covariance matrix & "deviation" vector
  S <- var(data)
  Sinv <- solve(S)
  ssize <- nrow(data)
  nvars <- ncol(data)
  xdel <- data - rep(1,ssize) %*% t(xbar)
  xdel <- as.matrix(xdel)
  
  cat("\nObs.","  ","Stat.distance\n")
  count <- 0
  sqd <- numeric(ssize)
  chsq <- numeric(ssize)
  
  # percentile point
  qcp <- qchisq(percent/100,nvars)
  
  for (i in 1:ssize) 
  {
    # squared distance
    sd <- xdel[i, ] %*% Sinv %*% xdel[i, ]
    
    # flag obs. outside the contour
    cat("\n",i,ifelse(i<10," ",""),":  ",round(sd,3),ifelse(sd>qcp ," +",""))
    if ( sd<=qcp ) count <- count+1
    
    sqd[i] <- sd
    chsq[i] <- qchisq(1-(ssize-i+0.5)/ssize,nvars)
  }
  
  plot(chsq,sort(sqd))
  abline(0,1)	#add reference line
  
  cat("\nThe proportion of observations falling into the ",percent,"% prob. contour is:\n",sep="")
  cat("  ",round(count/ssize,3))
}

#Compare % of observations inside the contour to the corresponding chisq percentile
chisqplot(percent=50)
chisqplot(percent=75)
chisqplot(data=hematol[,-5],percent=80)
```

The Chi-Square plot shows us the proportion of observations falling into the 50%, 75% and 80% probability contour are 0.51, 0.765, and 0.824 respectively. All three contour values are close to the percentile value. This tells us that the observed counts and the counts we expect are the same.
 
```{r}
# Formal test for normality (Shapiro-Wilks)
shapiro.test(hematol$V1)
shapiro.test(hematol$V2)
shapiro.test(hematol$V3)
shapiro.test(hematol$V4)
shapiro.test(hematol$V5)
shapiro.test(hematol$V6)
```

The null hypothesis for the Shapiro-Wilk test is that the data is normally distributed. Variables "White Blood Cell Count" (V3), "Lymphocyte Count" (V4), and "Serum Lead Concentration" (V6) all have a p-value less than the alpha level 0.05. This means that we reject the null hypothesis that those three variables are normally distributed. 

## In conclusion, based upon the results of our various plots and tests, Variables "Hemoglobin Concentration" (V1), "Packed Cell Volume" (V2), and "Neutrophil Count" (V5) are the most normally distributed variables among the hematology dataset. However, of these variables, the least skewed is "Neutrophil Count" (V5), with a p-value of 0.2516.

# 4.25 Use the glucose data in Table 3.9.

## (a) Use the methods in Section 4.5.1 to find the optimal univariate transformation to normality for each of the glucose measurements obtained one hour after sugar intake (x1, x2, and x3).

```{r}
# Univariate Transform to normality with Box-Cox 

# Get glucose table
t39<- read.table("T3_9_GLUCOSE.dat")
g <- as.data.frame(t39)
glucose <- g[,4:6]
names(glucose) <- c("x1", "x2", "x3")
 
library(MASS)

# Box-Cox Tranformations
boxcox(lm(x1 ~ 1, data=glucose))
boxcox(lm(x1 ~ 1, data=glucose), lambda=seq(0,1,1/100))
# lamda = 0.5

boxcox(lm(x2 ~ 1, data=glucose))
boxcox(lm(x2 ~ 1, data=glucose), lambda=seq(-.5,.2,1/100))
# lamda = -0.3

boxcox(lm(x3 ~ 1, data=glucose))
boxcox(lm(x3 ~ 1, data=glucose), lambda=seq(.5,1.5,1/100))
# lamda = 1.1
```

The Box-Cox univariate tranformations of $x_1, x_2,$ and $x_3$ gives us $\lambda$ of 0.5, -0.3, and 1.1 respectively. 

## (b) Use the methods in Section 4.5.2 to find the optimal multivariate transformation to 3-variate normality for the glucose measurements obtained one hour after sugar intake (x1, x2, and x3).

```{r}
# Multivariate Transform to 3-variate normality

library(carData)
library(car)

(pt <- powerTransform(glucose))
glucose.t <- data.frame(glucose, x1.t = (glucose$x1^pt$lambda[1]-1)/pt$lambda[1])
glucose.t <- data.frame(glucose.t, x2.t = (glucose$x2^pt$lambda[2]-1)/pt$lambda[2])
glucose.t <- data.frame(glucose.t, x3.t = (glucose$x3^pt$lambda[3]-1)/pt$lambda[3])

# Now lets take a look at the pairs plot before and after the transformation. Only viewing the new variables.
pairs(glucose[,1:3])
pairs(glucose.t[,4:6])
```

The multivariate power tranformations of $x_1, x_2,$ and $x_3$ gives us $\lambda$ of 0.7, 0, and 1.1 respectively.

## (c) How do the transformations obtained from the two approaches compare?

```{r}
# Using lamda to tranform the data

# Univariate Tranformations
a = 0.5
glucose$x1_uni = (glucose$x1)^a
b = -0.3
glucose$x2_uni = (glucose$x2)^b
c = 1.1
glucose$x3_uni = (glucose$x3)^c

# Multivariate Tranformations
aaa = 0.7
glucose$x1_multi = (glucose$x1)^aaa
bbb = 0
glucose$x2_multi = (glucose$x2)^bbb
ccc = 1.1
glucose$x3_multi = (glucose$x1)^ccc

head(glucose, 10)
```

Both univarite and multivarite transformations have the absolute difference in $\lambda$ values of 0.2, 0.3, and 0 for $x_1, x_2,$ and $x_3$ respectively. Looking at a glimpse of the new glucose dataset, we can see that after both transformations, the values for each variable are closer in range with one another than they were before. This shows that their distribution is more normal.









